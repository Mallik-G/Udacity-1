{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting feature_format.py\n"
     ]
    }
   ],
   "source": [
    " %%writefile feature_format.py\n",
    "# %load feature_format.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" \n",
    "    A general tool for converting data from the\n",
    "    dictionary format to an (n x k) python list that's \n",
    "    ready for training an sklearn algorithm\n",
    "\n",
    "    n--no. of key-value pairs in dictonary\n",
    "    k--no. of features being extracted\n",
    "\n",
    "    dictionary keys are names of persons in dataset\n",
    "    dictionary values are dictionaries, where each\n",
    "        key-value pair in the dict is the name\n",
    "        of a feature, and its value for that person\n",
    "\n",
    "    In addition to converting a dictionary to a numpy \n",
    "    array, you may want to separate the labels from the\n",
    "    features--this is what targetFeatureSplit is for\n",
    "\n",
    "    so, if you want to have the poi label as the target,\n",
    "    and the features you want to use are the person's\n",
    "    salary and bonus, here's what you would do:\n",
    "\n",
    "    feature_list = [\"poi\", \"salary\", \"bonus\"] \n",
    "    data_array = featureFormat( data_dictionary, feature_list )\n",
    "    label, features = targetFeatureSplit(data_array)\n",
    "\n",
    "    the line above (targetFeatureSplit) assumes that the\n",
    "    label is the _first_ item in feature_list--very important\n",
    "    that poi is listed first!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def featureFormat( dictionary, features, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False):\n",
    "    \"\"\" convert dictionary to numpy array of features\n",
    "        remove_NaN = True will convert \"NaN\" string to 0.0\n",
    "        remove_all_zeroes = True will omit any data points for which\n",
    "            all the features you seek are 0.0\n",
    "        remove_any_zeroes = True will omit any data points for which\n",
    "            any of the features you seek are 0.0\n",
    "        sort_keys = True sorts keys by alphabetical order. Setting the value as\n",
    "            a string opens the corresponding pickle file with a preset key\n",
    "            order (this is used for Python 3 compatibility, and sort_keys\n",
    "            should be left as False for the course mini-projects).\n",
    "        NOTE: first feature is assumed to be 'poi' and is not checked for\n",
    "            removal for zero or missing values.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return_list = []\n",
    "\n",
    "    # Key order - first branch is for Python 3 compatibility on mini-projects,\n",
    "    # second branch is for compatibility on final project.\n",
    "    if isinstance(sort_keys, str):\n",
    "        import pickle\n",
    "        keys = pickle.load(open(sort_keys, \"rb\"))\n",
    "    elif sort_keys:\n",
    "        keys = sorted(dictionary.keys())\n",
    "    else:\n",
    "        keys = dictionary.keys()\n",
    "\n",
    "    for key in keys:\n",
    "        tmp_list = []\n",
    "        for feature in features:\n",
    "            try:\n",
    "                dictionary[key][feature]\n",
    "            except KeyError:\n",
    "                print \"error: key \", feature, \" not present\"\n",
    "                return\n",
    "            value = dictionary[key][feature]\n",
    "            if value==\"NaN\" and remove_NaN:\n",
    "                value = 0\n",
    "            tmp_list.append( float(value) )\n",
    "\n",
    "        # Logic for deciding whether or not to add the data point.\n",
    "        append = True\n",
    "        # exclude 'poi' class as criteria.\n",
    "        if features[0] == 'poi':\n",
    "            test_list = tmp_list[1:]\n",
    "        else:\n",
    "            test_list = tmp_list\n",
    "        ### if all features are zero and you want to remove\n",
    "        ### data points that are all zero, do that here\n",
    "        if remove_all_zeroes:\n",
    "            append = False\n",
    "            for item in test_list:\n",
    "                if item != 0 and item != \"NaN\":\n",
    "                    append = True\n",
    "                    break\n",
    "        ### if any features for a given data point are zero\n",
    "        ### and you want to remove data points with any zeroes,\n",
    "        ### handle that here\n",
    "        if remove_any_zeroes:\n",
    "            if 0 in test_list or \"NaN\" in test_list:\n",
    "                append = False\n",
    "        ### Append the data point if flagged for addition.\n",
    "        if append:\n",
    "            return_list.append( np.array(tmp_list) )\n",
    "\n",
    "    return np.array(return_list)\n",
    "\n",
    "\n",
    "def targetFeatureSplit( data ):\n",
    "    \"\"\" \n",
    "        given a numpy array like the one returned from\n",
    "        featureFormat, separate out the first feature\n",
    "        and put it into its own list (this should be the \n",
    "        quantity you want to predict)\n",
    "\n",
    "        return targets and features as separate lists\n",
    "\n",
    "        (sklearn can generally handle both lists and numpy arrays as \n",
    "        input formats when training/predicting)\n",
    "    \"\"\"\n",
    "\n",
    "    target = []\n",
    "    features = []\n",
    "    for item in data:\n",
    "        target.append( item[0] )\n",
    "        features.append( item[1:] )\n",
    "\n",
    "    return target, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting outlier_removal_regression.py\n"
     ]
    }
   ],
   "source": [
    " %%writefile outlier_removal_regression.py\n",
    "# %load outlier_removal_regression.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "import random\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn import linear_model\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#from outlier_cleaner import outlierCleaner\n",
    "def outlierCleaner(predictions, ages, net_worths):\n",
    "    \"\"\"\n",
    "        clean away the 10% of points that have the largest\n",
    "        residual errors (different between the prediction\n",
    "        and the actual net worth)\n",
    "\n",
    "        return a list of tuples named cleaned_data where \n",
    "        each tuple is of the form (age, net_worth, error)\n",
    "    \"\"\"\n",
    "    \n",
    "    cleaned_data = []\n",
    "    \n",
    "    ### your code goes here\n",
    "   \n",
    "    netwerr = (net_worths-predictions)**2\n",
    "    databyerr = zip(ages,net_worths,netwerr)\n",
    "    databyerr = sorted(databyerr,key=lambda x:x[2][0],reverse=True)\n",
    "    sortlimit = int(len(databyerr)*0.1)\n",
    "    \n",
    "    cleaned_data = databyerr[sortlimit:]\n",
    "    \n",
    "    return cleaned_data\n",
    "\n",
    "\n",
    "\n",
    "### load up some practice data with outliers in it\n",
    "ages = pickle.load( open(\"data/practice_outliers_ages.pkl\", \"r\") )\n",
    "net_worths = pickle.load( open(\"data/practice_outliers_net_worths.pkl\", \"r\") )\n",
    "\n",
    "\n",
    "### ages and net_worths need to be reshaped into 2D numpy arrays\n",
    "### second argument of reshape command is a tuple of integers: (n_rows, n_columns)\n",
    "### by convention, n_rows is the number of data points\n",
    "### and n_columns is the number of features\n",
    "ages       = numpy.reshape( numpy.array(ages), (len(ages), 1))\n",
    "net_worths = numpy.reshape( numpy.array(net_worths), (len(net_worths), 1))\n",
    "from sklearn.cross_validation import train_test_split\n",
    "ages_train, ages_test, net_worths_train, net_worths_test = train_test_split(ages, net_worths, test_size=0.1, random_state=42)\n",
    "\n",
    "### fill in a regression here!  Name the regression object reg so that\n",
    "### the plotting code below works, and you can see what your regression looks like\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "reg.fit(ages_train,net_worths_train)\n",
    "\n",
    "cleaned_data = outlierCleaner(reg.predict(ages_train),ages_train,net_worths_train)\n",
    "cleaned_age = numpy.array([i[0] for i in cleaned_data])\n",
    "cleaned_netw = numpy.array([i[1] for i in cleaned_data])\n",
    "\n",
    "#reg.fit(cleaned_age,cleaned_netw)\n",
    "reg.fit(ages_train,net_worths_train)\n",
    "\n",
    "predict = reg.predict(net_worths_test)\n",
    "\n",
    "print \"What's the slope of your regression?\"\n",
    "slope = reg.coef_\n",
    "print slope\n",
    "\n",
    "intercept = reg.intercept_\n",
    "print intercept\n",
    "\n",
    "print \"What's the score when using your regression to make predictions with the test data?\"\n",
    "score = reg.score(ages_test,net_worths_test)\n",
    "print score\n",
    "\n",
    "\n",
    "try:\n",
    "    plt.plot(ages, reg.predict(ages), color=\"blue\")\n",
    "except NameError:\n",
    "    pass\n",
    "plt.scatter(ages, net_worths)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "### identify and remove the most outlier-y points\n",
    "cleaned_data = []\n",
    "try:\n",
    "    predictions = reg.predict(ages_train)\n",
    "    cleaned_data = outlierCleaner( predictions, ages_train, net_worths_train )\n",
    "except NameError:\n",
    "    print \"your regression object doesn't exist, or isn't name reg\"\n",
    "    print \"can't make predictions to use in identifying outliers\"\n",
    "\n",
    "\n",
    "\n",
    "### only run this code if cleaned_data is returning data\n",
    "if len(cleaned_data) > 0:\n",
    "    ages, net_worths, errors = zip(*cleaned_data)\n",
    "    ages       = numpy.reshape( numpy.array(ages), (len(ages), 1))\n",
    "    net_worths = numpy.reshape( numpy.array(net_worths), (len(net_worths), 1))\n",
    "\n",
    "    ### refit your cleaned data!\n",
    "    try:\n",
    "        reg.fit(ages, net_worths)\n",
    "        plt.plot(ages, reg.predict(ages), color=\"blue\")\n",
    "    except NameError:\n",
    "        print \"you don't seem to have regression imported/created,\"\n",
    "        print \"   or else your regression object isn't named reg\"\n",
    "        print \"   either way, only draw the scatter plot of the cleaned data\"\n",
    "    plt.scatter(ages, net_worths)\n",
    "    plt.xlabel(\"ages\")\n",
    "    plt.ylabel(\"net worths\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "else:\n",
    "    print \"outlierCleaner() is returning an empty list, no refitting to be done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting enron_outliers.py\n"
     ]
    }
   ],
   "source": [
    " %%writefile enron_outliers.py\n",
    "# %load enron_outliers.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "\n",
    "### read in data dictionary, convert to numpy array\n",
    "data_dict = pickle.load( open(\"data/final_project_dataset.pkl\", \"r\") )\n",
    "features = [\"salary\", \"bonus\"]\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "\n",
    "### your code below\n",
    "print \"Show the outliers on a scatter plot\"\n",
    "print data.max()\n",
    "\n",
    "for point in data:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    plt.scatter( salary, bonus )\n",
    "\n",
    "plt.xlabel(\"salary\")\n",
    "plt.ylabel(\"bonus\")\n",
    "\n",
    "\n",
    "print \"What is the source of the most extreme outlier?\"\n",
    "data_dict.pop('TOTAL',0)\n",
    "\n",
    "\n",
    "print \"What are the names associated with the current Enron outliers?\"\n",
    "outliers = []\n",
    "for key in data_dict:\n",
    "    val = data_dict[key]['salary']\n",
    "    if val == 'NaN':\n",
    "        continue\n",
    "    outliers.append((key,int(val)))\n",
    "\n",
    "print sorted(outliers,key=lambda x:x[1],reverse=True)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
